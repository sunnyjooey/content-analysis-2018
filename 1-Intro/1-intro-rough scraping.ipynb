{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreiving and Preparing Text for Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "import lucem_illud #pip install git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "import requests #for http requests\n",
    "import bs4 #called `beautifulsoup4`, an html parser\n",
    "import pandas as pd#gives us DataFrames\n",
    "import docx #reading MS doc files, install as `python-docx`\n",
    "\n",
    "#Stuff for pdfs\n",
    "#Install as `pdfminer2`\n",
    "import pdfminer.pdfinterp\n",
    "import pdfminer.converter\n",
    "import pdfminer.layout\n",
    "import pdfminer.pdfpage\n",
    "\n",
    "#These come with Python\n",
    "import re #for regexs\n",
    "import urllib \n",
    "import io #for making http requests look like files\n",
    "import json #For Tumblr API responses\n",
    "import os.path #For checking if files exist\n",
    "import os #For making directories\n",
    "\n",
    "from IPython.display import display\n",
    "#from bs4 import BeautifulSoup, NavigableString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Text (from saved .html files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countryDict = {\n",
    "'US': [\n",
    "\"us01.html\",\n",
    "\"us02.html\",\n",
    "\"us03.html\",\n",
    "\"us04.html\",\n",
    "\"us05.html\",\n",
    "\"us06.html\",\n",
    "\"us07.html\",\n",
    "\"us08.html\",\n",
    "\"us09.html\",\n",
    "\"us10.html\"\n",
    "]}              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loopThruArticles(countryDict):\n",
    "\n",
    "    parsDict = {'country': [], 'source': [], 'title': [], 'text': [], 'date': [], 'author': [], 'section': []}\n",
    "\n",
    "    for key, val in countryDict.items():\n",
    "        for html in val:\n",
    "            parsDict['country'].append(key)\n",
    "            parseArticle(html, parsDict)\n",
    "    \n",
    "    return parsDict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseArticle(html, parsDict):\n",
    "    soup = bs4.BeautifulSoup(open(html, 'rt', encoding='UTF8'),'lxml')\n",
    "\n",
    "    # title\n",
    "    title0 = soup.find_all('div', {'class' : 'title'})\n",
    "    title1 = title0[0].text.replace('Hide Details', '') #cleaning\n",
    "    title = re.sub(r'\\<.*\\>', '', title1)\n",
    "    parsDict['title'].append(title)\n",
    "\n",
    "    # text\n",
    "    body = soup.find_all('div', {'class' : 'body'})\n",
    "    text0 = \"\".join([t for t in body[0].contents if type(t)==bs4.element.NavigableString]) #get text only from content, not children\n",
    "    text1 = re.sub(r\"Source- .+\",\"\", text0) #cleaning\n",
    "    text2 = re.sub(r\"© .+\",\"\", text1) #cleaning\n",
    "    text3 = re.sub(r\"(STORY CAN END HERE)\",\"\", text2) #cleaning \n",
    "    text4 = re.sub(r\"(EDITORS: STORY CAN END HERE)\",\"\", text3) #cleaning\n",
    "    text5 = re.sub(r\"(EDITORS: )\",\"\", text4) #cleaning\n",
    "    text = re.sub(r\"^([A-Z]+)\", \"\", text5) #take out first word if all caps (it is a location)\n",
    "    parsDict['text'].append(text)\n",
    "    \n",
    "#     with open(\"%s.txt\" % html[:-5], \"w\", encoding='UTF-8') as text_file:\n",
    "#         text_file.write(text)\n",
    "\n",
    "    # source & date\n",
    "    source = soup.find_all('div', {'class' : 'source'})\n",
    "    date = re.findall(r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{1,2},\\s\\d{4}', source[0].text)\n",
    "    parsDict['date'].append(date[0])\n",
    "    pat2 = re.compile(r\"(.*?)-\\s\", re.M)\n",
    "    newssource = pat2.findall(source[0].text)\n",
    "    parsDict['source'].append(newssource[0])\n",
    "\n",
    "    # author  \n",
    "    author0 = soup.find_all('span', {'class' : 'val'})\n",
    "    author = re.sub(r'\\<.*\\>', '', author0[0].text) #Take out <>\n",
    "    parsDict['author'].append(author)\n",
    "\n",
    "    # section\n",
    "    section0 = soup.find_all('span', {'class' : 'lbl'}, string=\"Section: \")\n",
    "    section = section0[0].next_element.next_element.next_element.text\n",
    "    #section = re.sub(r'\\<.*\\>', '', section0.text) #Take out <>\n",
    "    parsDict['section'].append(section)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(loopThruArticles(countryDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>section</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sheryl DeVore, News-Sun</td>\n",
       "      <td>US</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Libertyville Review (IL)</td>\n",
       "      <td>ibertyville High School senior Leah Hartung le...</td>\n",
       "      <td>'No argument' climate\\nchange man-made - \\nFor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheryl DeVore, News-Sun</td>\n",
       "      <td>US</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Mundelein Review (IL)</td>\n",
       "      <td>ibertyville High School senior Leah Hartung le...</td>\n",
       "      <td>'No argument' climate\\nchange man-made - \\nFor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kirt Manion, kmanion@ncnewspress.com</td>\n",
       "      <td>US</td>\n",
       "      <td>November 10, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Nebraska City News-Press (NE)</td>\n",
       "      <td>hen people discuss the topic of \\n, most of th...</td>\n",
       "      <td>UNL scientist discusses state impact of climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sheryl DeVore, News-Sun</td>\n",
       "      <td>US</td>\n",
       "      <td>November 10, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Lake County News-Sun (Waukegan, IL)</td>\n",
       "      <td>ibertyville High School senior Leah Hartung le...</td>\n",
       "      <td>'No argument' climate\\nchange man-made - \\nFor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stuart Leavenworth, Staff Writer</td>\n",
       "      <td>US</td>\n",
       "      <td>November 5, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Belleville News-Democrat (IL) (Published as Be...</td>\n",
       "      <td>The Trump administration released a sweeping ...</td>\n",
       "      <td>Climate\\nchange sucks moisture from West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stuart Leavenworth \\nMcClatchy Washington Bureau</td>\n",
       "      <td>US</td>\n",
       "      <td>November 4, 2017</td>\n",
       "      <td>A</td>\n",
       "      <td>Skagit Valley Herald (Mount Vernon, WA)</td>\n",
       "      <td>— The Trump administration released a sweepin...</td>\n",
       "      <td>Fed study: Climate\\nchange sucks moisture from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LISA FRIEDMAN New York Times Service</td>\n",
       "      <td>US</td>\n",
       "      <td>November 4, 2017</td>\n",
       "      <td>Front Page</td>\n",
       "      <td>Daily Gazette, The (Schenectady, NY)</td>\n",
       "      <td>-- Directly contradicting much of the Trump  ...</td>\n",
       "      <td>Climate report at odds with Trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LISA FRIEDMAN</td>\n",
       "      <td>US</td>\n",
       "      <td>November 4, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Tri-City Herald (Kennewick, WA)</td>\n",
       "      <td>Directly contradicting much of the Trump admi...</td>\n",
       "      <td>US report contradicts Trump on cause of climat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CHANK KIEU theconversation.com</td>\n",
       "      <td>US</td>\n",
       "      <td>September 20, 2017</td>\n",
       "      <td>News</td>\n",
       "      <td>Times and Democrat, The (Orangeburg, SC)</td>\n",
       "      <td>urricane Harvey, with its historical amount of...</td>\n",
       "      <td>Do hurricanes feel the effects of climate\\ncha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chanh Kieu \\nIndiana University</td>\n",
       "      <td>US</td>\n",
       "      <td>September 13, 2017</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "      <td>Alva Review-Courier (OK)</td>\n",
       "      <td>o hurricanes feel the effects of \\n?\\n(The Con...</td>\n",
       "      <td>Do hurricanes feel the effects of climate\\ncha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             author country  \\\n",
       "0                           Sheryl DeVore, News-Sun      US   \n",
       "1                           Sheryl DeVore, News-Sun      US   \n",
       "2              Kirt Manion, kmanion@ncnewspress.com      US   \n",
       "3                           Sheryl DeVore, News-Sun      US   \n",
       "4                  Stuart Leavenworth, Staff Writer      US   \n",
       "5  Stuart Leavenworth \\nMcClatchy Washington Bureau      US   \n",
       "6              LISA FRIEDMAN New York Times Service      US   \n",
       "7                                     LISA FRIEDMAN      US   \n",
       "8                    CHANK KIEU theconversation.com      US   \n",
       "9                   Chanh Kieu \\nIndiana University      US   \n",
       "\n",
       "                 date               section  \\\n",
       "0   November 16, 2017                  News   \n",
       "1   November 16, 2017                  News   \n",
       "2   November 10, 2017                  News   \n",
       "3   November 10, 2017                  News   \n",
       "4    November 5, 2017                  News   \n",
       "5    November 4, 2017                     A   \n",
       "6    November 4, 2017            Front Page   \n",
       "7    November 4, 2017                  News   \n",
       "8  September 20, 2017                  News   \n",
       "9  September 13, 2017  Science & Technology   \n",
       "\n",
       "                                              source  \\\n",
       "0                          Libertyville Review (IL)    \n",
       "1                             Mundelein Review (IL)    \n",
       "2                     Nebraska City News-Press (NE)    \n",
       "3               Lake County News-Sun (Waukegan, IL)    \n",
       "4  Belleville News-Democrat (IL) (Published as Be...   \n",
       "5           Skagit Valley Herald (Mount Vernon, WA)    \n",
       "6              Daily Gazette, The (Schenectady, NY)    \n",
       "7                   Tri-City Herald (Kennewick, WA)    \n",
       "8          Times and Democrat, The (Orangeburg, SC)    \n",
       "9                          Alva Review-Courier (OK)    \n",
       "\n",
       "                                                text  \\\n",
       "0  ibertyville High School senior Leah Hartung le...   \n",
       "1  ibertyville High School senior Leah Hartung le...   \n",
       "2  hen people discuss the topic of \\n, most of th...   \n",
       "3  ibertyville High School senior Leah Hartung le...   \n",
       "4   The Trump administration released a sweeping ...   \n",
       "5   — The Trump administration released a sweepin...   \n",
       "6   -- Directly contradicting much of the Trump  ...   \n",
       "7   Directly contradicting much of the Trump admi...   \n",
       "8  urricane Harvey, with its historical amount of...   \n",
       "9  o hurricanes feel the effects of \\n?\\n(The Con...   \n",
       "\n",
       "                                               title  \n",
       "0  'No argument' climate\\nchange man-made - \\nFor...  \n",
       "1  'No argument' climate\\nchange man-made - \\nFor...  \n",
       "2  UNL scientist discusses state impact of climat...  \n",
       "3  'No argument' climate\\nchange man-made - \\nFor...  \n",
       "4           Climate\\nchange sucks moisture from West  \n",
       "5  Fed study: Climate\\nchange sucks moisture from...  \n",
       "6                  Climate report at odds with Trump  \n",
       "7  US report contradicts Trump on cause of climat...  \n",
       "8  Do hurricanes feel the effects of climate\\ncha...  \n",
       "9  Do hurricanes feel the effects of climate\\ncha...  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
